{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Application Platforms', 'Applications', 'Business Applications', 'Cloud Services', 'Communications & Networking', 'Database & Business Intelligence', 'Development Applications', 'General', 'Job Titles', 'Libraries, Frameworks & Software Standards', 'Miscellaneous', 'Operating Systems', 'Processes & Methodologies', 'Programming Languages', 'Qualifications', 'Quality Assurance & Compliance', 'System Software', 'Systems Management', 'Vendors']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "job_list=[]\n",
    "link_list=[]\n",
    "top30=[]\n",
    "it_skills_list=[]\n",
    "\n",
    "for page_number in range (1,2):\n",
    "\n",
    "    main_url=\"http://www.itjobswatch.co.uk\"\n",
    "    my_url = (\"https://www.itjobswatch.co.uk/default.aspx?page={}\".format(page_number) + \"&sortby=0&orderby=0&q=&id=0&lid=2618\")\n",
    "        \n",
    "    page = requests.get(my_url).text\n",
    "    soup=BeautifulSoup (page, \"html.parser\")\n",
    "    \n",
    "    #JOB LIST\n",
    "    for job in soup.findAll(\"table\", attrs={\"class\":\"results\"}):\n",
    "        for kk in job.findAll(\"td\", \"c2\"):\n",
    "            job_list.append(kk.text)\n",
    "    \n",
    "    #LINK LIST \n",
    "    for aa in soup.findAll(\"td\", \"c2\"):\n",
    "        for bb in aa.findAll(\"a\"):\n",
    "            link_list.append(main_url + bb.get(\"href\"))        \n",
    "\n",
    "    #TOP 30 LIST (IN EVERY SUB-PAGE)\n",
    "    for linknumber in range(0, len(link_list)):\n",
    "        top30_key=[]\n",
    "        top30_value=[]\n",
    "        top30=[]\n",
    "\n",
    "        page1 = requests.get(link_list[linknumber]).text\n",
    "        soup1=BeautifulSoup (page1, \"html.parser\")\n",
    "        \n",
    "        topthirty= soup1.findAll(\"table\", attrs={\"class\":\"itab\"})\n",
    "        aa=topthirty[0].findAll(\"td\", \"cd\")\n",
    "        aa_value=topthirty[0].findAll(\"td\", \"cp\")\n",
    "        \n",
    "        bb=topthirty[1].findAll(\"td\", \"cd\")\n",
    "        bb_value=topthirty[1].findAll(\"td\", \"cp\")\n",
    "\n",
    "\n",
    "        for ii in zip(aa, aa_value):\n",
    "            top30_key.append(aa.ii.text)\n",
    "            top30_value.append(aa_value.ii.text)\n",
    "            \n",
    "        for jj in zip(bb, bb_value):\n",
    "            top30_key.append(bb.jj.text)\n",
    "            top30_value.append(bb_value.jj.text)        \n",
    "        sonuc={job_list[linknumber]:{\"Top 30\":{top30_top30}}\n",
    "        #print(sonuc)\n",
    "    \n",
    "    #IT SKILLS LIST\n",
    "    it_skills= soup1.findAll(\"ul\", attrs={\"id\":\"skill-set-nav\"})\n",
    "    for ul_li in it_skills:\n",
    "        tt=ul_li.findAll(\"a\")\n",
    "    for zz in tt:\n",
    "        it_skills_list.append(zz.text)\n",
    "        \n",
    "     \n",
    "        \n",
    "        \n",
    "\n",
    "#print(job_list)\n",
    "#print(link_list)\n",
    "#print(top30)\n",
    "print(it_skills_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "job_list=[]\n",
    "link_list=[]\n",
    "top30=[]\n",
    "\n",
    "for page_number in range (1,2):\n",
    "    main_url=\"http://www.itjobswatch.co.uk\"\n",
    "    my_url = (\"https://www.itjobswatch.co.uk/default.aspx?page={}\".format(page_number) + \"&sortby=0&orderby=0&q=&id=0&lid=2618\")\n",
    "        \n",
    "    page = requests.get(my_url).text\n",
    "    soup=BeautifulSoup (page, \"html.parser\")\n",
    "    #JOB LIST\n",
    "    for job in soup.findAll(\"table\", attrs={\"class\":\"results\"}):\n",
    "        for kk in job.findAll(\"td\", \"c2\"):\n",
    "            job_list.append(kk.text)\n",
    "    \n",
    "    #LINK LIST \n",
    "    for aa in soup.findAll(\"td\", \"c2\"):\n",
    "        for bb in aa.findAll(\"a\"):\n",
    "            link_list.append(main_url + bb.get(\"href\"))        \n",
    "\n",
    "            #TOP 30 LIST (IN EVERY SUB-PAGE)\n",
    "            page1 = requests.get(main_url+bb.get(\"href\")).text\n",
    "            soup1=BeautifulSoup (page1, \"html.parser\")\n",
    "            for topthirty in soup1.findAll(\"div\", attrs={\"class\":\"container\"}):\n",
    "                for cc in topthirty.findAll(\"table\"):\n",
    "                #for cc in topthirty.findAll(\"td\", attrs={\"class\":\"tabRelatedGroupsContainer\"}):\n",
    "                    for dd in cc.findAll(\"td\", attrs={\"class\":\"cd\"}):\n",
    "                        top30.append(dd.text)\n",
    "                        \n",
    "                        #/html/body/div[1]/table[2]/tbody/tr/td[1]/table[2]/tbody/tr/td/div/table[1]\n",
    "print(job_list)\n",
    "print(link_list)\n",
    "print(top30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
